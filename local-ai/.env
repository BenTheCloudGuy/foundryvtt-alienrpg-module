# Default model to pull on first start.
# Change this to any model available on ollama.com/library
# Recommended for MU/TH/UR:
#   llama3.1:8b      — Fast, good quality, ~4.7GB (default)
#   llama3.1:70b     — Higher quality, needs ~40GB VRAM
#   mistral:7b       — Fast alternative, ~4.1GB
#   phi3:mini        — Lightweight, ~2.3GB
OLLAMA_MODEL=llama3.1:8b
